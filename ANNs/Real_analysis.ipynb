{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from models import save_model, generate_model_CNN, generate_model_LSTM, plot_performance\n",
    "from generators import generator, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'plots'\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "X_train = np.load('../data/final_data/X_train.npy')\n",
    "y_train = np.load('../data/final_data/y_train.npy')\n",
    "\n",
    "\n",
    "X_test = np.load('../data/final_data/X_test.npy')\n",
    "y_test = np.load('../data/final_data/y_test.npy')\n",
    "\n",
    "\n",
    "X = np.load('../data/final_data/X.npy')\n",
    "y = np.load('../data/final_data/y.npy')\n",
    "\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "y = enc.fit_transform(y.reshape(-1, 1) ,).toarray()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1, 1) ,).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1, 1) ,).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "time_window = X_test.shape[1]\n",
    "n_dim = X_test.shape[2]\n",
    "predict_early = 0\n",
    "\n",
    "input_shape = (time_window, n_dim)\n",
    "class_weight = {0: 1., 1: 1.,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 20)          1760      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,082\n",
      "Trainable params: 5,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input_shape = (time_window, n_dim)\n",
    "# model = generate_model_CNN(input_shape)\n",
    "\n",
    "input_shape = (None, n_dim)\n",
    "model = generate_model_LSTM(input_shape)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1205 samples, validate on 392 samples\n",
      "Epoch 1/15\n",
      "1205/1205 [==============================] - 19s 16ms/step - loss: 0.6341 - acc: 0.6664 - val_loss: 0.5409 - val_acc: 0.7908\n",
      "Epoch 2/15\n",
      "1205/1205 [==============================] - 17s 14ms/step - loss: 0.6332 - acc: 0.6647 - val_loss: 0.5288 - val_acc: 0.7908\n",
      "Epoch 3/15\n",
      "1205/1205 [==============================] - 14s 11ms/step - loss: 0.6290 - acc: 0.6697 - val_loss: 0.5607 - val_acc: 0.7908\n",
      "Epoch 4/15\n",
      "1205/1205 [==============================] - 12s 10ms/step - loss: 0.6291 - acc: 0.6689 - val_loss: 0.5547 - val_acc: 0.7908\n",
      "Epoch 5/15\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.6261 - acc: 0.6705 - val_loss: 0.5685 - val_acc: 0.7908\n",
      "Epoch 6/15\n",
      "1205/1205 [==============================] - 20s 17ms/step - loss: 0.6288 - acc: 0.6730 - val_loss: 0.5485 - val_acc: 0.7908\n",
      "Epoch 7/15\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.6270 - acc: 0.6697 - val_loss: 0.5570 - val_acc: 0.7908\n",
      "Epoch 8/15\n",
      "1205/1205 [==============================] - 17s 14ms/step - loss: 0.6269 - acc: 0.6730 - val_loss: 0.5549 - val_acc: 0.7908\n",
      "Epoch 9/15\n",
      "1205/1205 [==============================] - 13s 11ms/step - loss: 0.6293 - acc: 0.6755 - val_loss: 0.5587 - val_acc: 0.7832\n",
      "Epoch 10/15\n",
      "1205/1205 [==============================] - 18s 15ms/step - loss: 0.6242 - acc: 0.6722 - val_loss: 0.5406 - val_acc: 0.7908\n",
      "Epoch 11/15\n",
      "1205/1205 [==============================] - 15s 13ms/step - loss: 0.6256 - acc: 0.6772 - val_loss: 0.5618 - val_acc: 0.7857\n",
      "Epoch 12/15\n",
      "1205/1205 [==============================] - 15s 13ms/step - loss: 0.6248 - acc: 0.6763 - val_loss: 0.5442 - val_acc: 0.7908\n",
      "Epoch 13/15\n",
      "1205/1205 [==============================] - 15s 13ms/step - loss: 0.6253 - acc: 0.6763 - val_loss: 0.5683 - val_acc: 0.7857\n",
      "Epoch 14/15\n",
      " 750/1205 [=================>............] - ETA: 4s - loss: 0.6308 - acc: 0.6773"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=50,\n",
    "                    epochs=15, \n",
    "                    verbose=1,\n",
    "                    validation_data = (X_test, y_test),\n",
    "#                     class_weight=class_weight,\n",
    "                    )\n",
    "\n",
    "save_model(model, name=predict_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from generators import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decode(res, threshold=0.5)\n",
    "y_true = decode(y_test, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision_score: ', np.round(precision_score(y_true, y_pred, average='binary', pos_label=1), decimals=3))\n",
    "print('recall_score: ', np.round(recall_score(y_true, y_pred, average='binary', pos_label=1), decimals=3))\n",
    "print('')\n",
    "print('precision_score: ', np.round(precision_score(y_true, y_pred, average='binary', pos_label=0), decimals=3))\n",
    "print('recall_score: ', np.round(recall_score(y_true, y_pred, average='binary', pos_label=0), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(cm/cm.sum(axis=1)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_pred[mask])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_true == 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
